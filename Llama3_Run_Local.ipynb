{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaac179b",
   "metadata": {},
   "source": [
    "# Project: Running Llama 3.0 Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af9206b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -qU langchain langchain_community langchain-openai langchainhub langchain-ollama "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9585abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt update && sudo apt upgrade --assume-yes\n",
    "!sudo apt install curl --assume-yes\n",
    "!curl --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb56f758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Downloading ollama...\n",
      "######################################################################## 100.0%#=#=#                                                                         \n",
      ">>> Installing ollama to /usr/local/bin...\n",
      "WARNING: Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
      ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
      ">>> Install complete. Run \"ollama\" from the command line.\n"
     ]
    }
   ],
   "source": [
    "!curl -fsSL https://ollama.com/install.sh | sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7bb224",
   "metadata": {},
   "source": [
    "llama3.1 is abbreviation for the llama3 8B model.\n",
    "\n",
    "At least 6 GiB of free space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1999d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama serve\n",
    "!ollama run llama3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19fe27b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c9d6a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a7d2512-f7be-474d-936f-a24981a355b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are an assistant that knows about Llama 3.1 training. \n",
    "    \n",
    "    If you don't know the answer, just say that you don't know. \n",
    "    \n",
    "    Use three sentences maximum and keep the answer concise:\n",
    "\n",
    "    Question: {question} \n",
    "\n",
    "    Answer: \n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"documents\"],\n",
    ")\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.1\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "671c460d-f5bf-4a80-bab6-86453aececa4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectError",
     "evalue": "[Errno 111] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpx/_transports/default.py:69\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 69\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpx/_transports/default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 233\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pool\u001b[39m.\u001b[39;49mhandle_request(req)\n\u001b[1;32m    235\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(resp\u001b[39m.\u001b[39mstream, typing\u001b[39m.\u001b[39mIterable)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[39mraise\u001b[39;00m exc \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[39m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[39m# the point at which the response is closed.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[39m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mhandle_request(\n\u001b[1;32m    197\u001b[0m         pool_request\u001b[39m.\u001b[39;49mrequest\n\u001b[1;32m    198\u001b[0m     )\n\u001b[1;32m    199\u001b[0m \u001b[39mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[39m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[39m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[39m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpcore/_sync/connection.py:99\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_connect_failed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m     \u001b[39mraise\u001b[39;00m exc\n\u001b[1;32m    101\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_connection\u001b[39m.\u001b[39mhandle_request(request)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpcore/_sync/connection.py:76\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_connection \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_connect(request)\n\u001b[1;32m     78\u001b[0m     ssl_object \u001b[39m=\u001b[39m stream\u001b[39m.\u001b[39mget_extra_info(\u001b[39m\"\u001b[39m\u001b[39mssl_object\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpcore/_sync/connection.py:122\u001b[0m, in \u001b[0;36mHTTPConnection._connect\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mwith\u001b[39;00m Trace(\u001b[39m\"\u001b[39m\u001b[39mconnect_tcp\u001b[39m\u001b[39m\"\u001b[39m, logger, request, kwargs) \u001b[39mas\u001b[39;00m trace:\n\u001b[0;32m--> 122\u001b[0m     stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_network_backend\u001b[39m.\u001b[39;49mconnect_tcp(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    123\u001b[0m     trace\u001b[39m.\u001b[39mreturn_value \u001b[39m=\u001b[39m stream\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpcore/_backends/sync.py:205\u001b[0m, in \u001b[0;36mSyncBackend.connect_tcp\u001b[0;34m(self, host, port, timeout, local_address, socket_options)\u001b[0m\n\u001b[1;32m    200\u001b[0m exc_map: ExceptionMapping \u001b[39m=\u001b[39m {\n\u001b[1;32m    201\u001b[0m     socket\u001b[39m.\u001b[39mtimeout: ConnectTimeout,\n\u001b[1;32m    202\u001b[0m     \u001b[39mOSError\u001b[39;00m: ConnectError,\n\u001b[1;32m    203\u001b[0m }\n\u001b[0;32m--> 205\u001b[0m \u001b[39mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    206\u001b[0m     sock \u001b[39m=\u001b[39m socket\u001b[39m.\u001b[39mcreate_connection(\n\u001b[1;32m    207\u001b[0m         address,\n\u001b[1;32m    208\u001b[0m         timeout,\n\u001b[1;32m    209\u001b[0m         source_address\u001b[39m=\u001b[39msource_address,\n\u001b[1;32m    210\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen\u001b[39m.\u001b[39;49mthrow(typ, value, traceback)\n\u001b[1;32m    154\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    155\u001b[0m     \u001b[39m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[39m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[39m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpcore/_exceptions.py:14\u001b[0m, in \u001b[0;36mmap_exceptions\u001b[0;34m(map)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(exc, from_exc):\n\u001b[0;32m---> 14\u001b[0m         \u001b[39mraise\u001b[39;00m to_exc(exc) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mConnectError\u001b[0m: [Errno 111] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mConnectError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/sagemaker-user/rag_agents/Llama3_Run_Local.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://7tub6elf8fprf6d.studio.us-east-1.sagemaker.aws/home/sagemaker-user/rag_agents/Llama3_Run_Local.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m chain\u001b[39m.\u001b[39;49minvoke({\u001b[39m'\u001b[39;49m\u001b[39mquestion\u001b[39;49m\u001b[39m'\u001b[39;49m:\u001b[39m'\u001b[39;49m\u001b[39mWhen was the LLM Llama 3.1 trained?\u001b[39;49m\u001b[39m'\u001b[39;49m})\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_core/runnables/base.py:2875\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2873\u001b[0m             \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39minvoke(\u001b[39minput\u001b[39m, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   2874\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2875\u001b[0m             \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39;49minvoke(\u001b[39minput\u001b[39;49m, config)\n\u001b[1;32m   2876\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[1;32m   2877\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:274\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvoke\u001b[39m(\n\u001b[1;32m    264\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    265\u001b[0m     \u001b[39minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    270\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m BaseMessage:\n\u001b[1;32m    271\u001b[0m     config \u001b[39m=\u001b[39m ensure_config(config)\n\u001b[1;32m    272\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(\n\u001b[1;32m    273\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 274\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_prompt(\n\u001b[1;32m    275\u001b[0m             [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convert_input(\u001b[39minput\u001b[39;49m)],\n\u001b[1;32m    276\u001b[0m             stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    277\u001b[0m             callbacks\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcallbacks\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    278\u001b[0m             tags\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mtags\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    279\u001b[0m             metadata\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmetadata\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    280\u001b[0m             run_name\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mrun_name\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    281\u001b[0m             run_id\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39mrun_id\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    282\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    283\u001b[0m         )\u001b[39m.\u001b[39mgenerations[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m],\n\u001b[1;32m    284\u001b[0m     )\u001b[39m.\u001b[39mmessage\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:714\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[1;32m    707\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    708\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    712\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    713\u001b[0m     prompt_messages \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_messages() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[0;32m--> 714\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_messages, stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:571\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[39mif\u001b[39;00m run_managers:\n\u001b[1;32m    570\u001b[0m             run_managers[i]\u001b[39m.\u001b[39mon_llm_error(e, response\u001b[39m=\u001b[39mLLMResult(generations\u001b[39m=\u001b[39m[]))\n\u001b[0;32m--> 571\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    572\u001b[0m flattened_outputs \u001b[39m=\u001b[39m [\n\u001b[1;32m    573\u001b[0m     LLMResult(generations\u001b[39m=\u001b[39m[res\u001b[39m.\u001b[39mgenerations], llm_output\u001b[39m=\u001b[39mres\u001b[39m.\u001b[39mllm_output)  \u001b[39m# type: ignore[list-item]\u001b[39;00m\n\u001b[1;32m    574\u001b[0m     \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results\n\u001b[1;32m    575\u001b[0m ]\n\u001b[1;32m    576\u001b[0m llm_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_combine_llm_outputs([res\u001b[39m.\u001b[39mllm_output \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results])\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:561\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[39mfor\u001b[39;00m i, m \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(messages):\n\u001b[1;32m    559\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    560\u001b[0m         results\u001b[39m.\u001b[39mappend(\n\u001b[0;32m--> 561\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_with_cache(\n\u001b[1;32m    562\u001b[0m                 m,\n\u001b[1;32m    563\u001b[0m                 stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    564\u001b[0m                 run_manager\u001b[39m=\u001b[39;49mrun_managers[i] \u001b[39mif\u001b[39;49;00m run_managers \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    565\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    566\u001b[0m             )\n\u001b[1;32m    567\u001b[0m         )\n\u001b[1;32m    568\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m         \u001b[39mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:793\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    791\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    792\u001b[0m     \u001b[39mif\u001b[39;00m inspect\u001b[39m.\u001b[39msignature(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 793\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(\n\u001b[1;32m    794\u001b[0m             messages, stop\u001b[39m=\u001b[39;49mstop, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    795\u001b[0m         )\n\u001b[1;32m    796\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(messages, stop\u001b[39m=\u001b[39mstop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_ollama/chat_models.py:617\u001b[0m, in \u001b[0;36mChatOllama._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_generate\u001b[39m(\n\u001b[1;32m    611\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    612\u001b[0m     messages: List[BaseMessage],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    616\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ChatResult:\n\u001b[0;32m--> 617\u001b[0m     final_chunk \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_chat_stream_with_aggregation(\n\u001b[1;32m    618\u001b[0m         messages, stop, run_manager, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    619\u001b[0m     )\n\u001b[1;32m    620\u001b[0m     generation_info \u001b[39m=\u001b[39m final_chunk\u001b[39m.\u001b[39mgeneration_info\n\u001b[1;32m    621\u001b[0m     chat_generation \u001b[39m=\u001b[39m ChatGeneration(\n\u001b[1;32m    622\u001b[0m         message\u001b[39m=\u001b[39mAIMessage(\n\u001b[1;32m    623\u001b[0m             content\u001b[39m=\u001b[39mfinal_chunk\u001b[39m.\u001b[39mtext,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    627\u001b[0m         generation_info\u001b[39m=\u001b[39mgeneration_info,\n\u001b[1;32m    628\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_ollama/chat_models.py:518\u001b[0m, in \u001b[0;36mChatOllama._chat_stream_with_aggregation\u001b[0;34m(self, messages, stop, run_manager, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_chat_stream_with_aggregation\u001b[39m(\n\u001b[1;32m    510\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    511\u001b[0m     messages: List[BaseMessage],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    516\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ChatGenerationChunk:\n\u001b[1;32m    517\u001b[0m     final_chunk \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 518\u001b[0m     \u001b[39mfor\u001b[39;00m stream_resp \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_chat_stream(messages, stop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    519\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(stream_resp, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    520\u001b[0m             chunk \u001b[39m=\u001b[39m ChatGenerationChunk(\n\u001b[1;32m    521\u001b[0m                 message\u001b[39m=\u001b[39mAIMessageChunk(\n\u001b[1;32m    522\u001b[0m                     content\u001b[39m=\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    535\u001b[0m                 ),\n\u001b[1;32m    536\u001b[0m             )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_ollama/chat_models.py:500\u001b[0m, in \u001b[0;36mChatOllama._create_chat_stream\u001b[0;34m(self, messages, stop, **kwargs)\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[39myield\u001b[39;00m Client(host\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbase_url)\u001b[39m.\u001b[39mchat(\n\u001b[1;32m    491\u001b[0m         model\u001b[39m=\u001b[39mparams[\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m    492\u001b[0m         messages\u001b[39m=\u001b[39mollama_messages,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    497\u001b[0m         tools\u001b[39m=\u001b[39mkwargs[\u001b[39m\"\u001b[39m\u001b[39mtools\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    499\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 500\u001b[0m     \u001b[39myield from\u001b[39;00m Client(host\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbase_url)\u001b[39m.\u001b[39mchat(\n\u001b[1;32m    501\u001b[0m         model\u001b[39m=\u001b[39mparams[\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m    502\u001b[0m         messages\u001b[39m=\u001b[39mollama_messages,\n\u001b[1;32m    503\u001b[0m         stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    504\u001b[0m         options\u001b[39m=\u001b[39mOptions(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams[\u001b[39m\"\u001b[39m\u001b[39moptions\u001b[39m\u001b[39m\"\u001b[39m]),\n\u001b[1;32m    505\u001b[0m         keep_alive\u001b[39m=\u001b[39mparams[\u001b[39m\"\u001b[39m\u001b[39mkeep_alive\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m    506\u001b[0m         \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39mparams[\u001b[39m\"\u001b[39m\u001b[39mformat\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m    507\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ollama/_client.py:79\u001b[0m, in \u001b[0;36mClient._stream\u001b[0;34m(self, method, url, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_stream\u001b[39m(\u001b[39mself\u001b[39m, method: \u001b[39mstr\u001b[39m, url: \u001b[39mstr\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Mapping[\u001b[39mstr\u001b[39m, Any]]:\n\u001b[0;32m---> 79\u001b[0m   \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client\u001b[39m.\u001b[39mstream(method, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mas\u001b[39;00m r:\n\u001b[1;32m     80\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m       r\u001b[39m.\u001b[39mraise_for_status()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc\n\u001b[1;32m    134\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[1;32m    136\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mgenerator didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt yield\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpx/_client.py:870\u001b[0m, in \u001b[0;36mClient.stream\u001b[0;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    848\u001b[0m \u001b[39mAlternative to `httpx.request()` that streams the response body\u001b[39;00m\n\u001b[1;32m    849\u001b[0m \u001b[39minstead of loading it into memory at once.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[39m[0]: /quickstart#streaming-responses\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    857\u001b[0m request \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuild_request(\n\u001b[1;32m    858\u001b[0m     method\u001b[39m=\u001b[39mmethod,\n\u001b[1;32m    859\u001b[0m     url\u001b[39m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    868\u001b[0m     extensions\u001b[39m=\u001b[39mextensions,\n\u001b[1;32m    869\u001b[0m )\n\u001b[0;32m--> 870\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(\n\u001b[1;32m    871\u001b[0m     request\u001b[39m=\u001b[39;49mrequest,\n\u001b[1;32m    872\u001b[0m     auth\u001b[39m=\u001b[39;49mauth,\n\u001b[1;32m    873\u001b[0m     follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    874\u001b[0m     stream\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    875\u001b[0m )\n\u001b[1;32m    876\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    877\u001b[0m     \u001b[39myield\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    906\u001b[0m follow_redirects \u001b[39m=\u001b[39m (\n\u001b[1;32m    907\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfollow_redirects\n\u001b[1;32m    908\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m    909\u001b[0m     \u001b[39melse\u001b[39;00m follow_redirects\n\u001b[1;32m    910\u001b[0m )\n\u001b[1;32m    912\u001b[0m auth \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_auth(\n\u001b[1;32m    915\u001b[0m     request,\n\u001b[1;32m    916\u001b[0m     auth\u001b[39m=\u001b[39;49mauth,\n\u001b[1;32m    917\u001b[0m     follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    918\u001b[0m     history\u001b[39m=\u001b[39;49m[],\n\u001b[1;32m    919\u001b[0m )\n\u001b[1;32m    920\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_redirects(\n\u001b[1;32m    943\u001b[0m         request,\n\u001b[1;32m    944\u001b[0m         follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    945\u001b[0m         history\u001b[39m=\u001b[39;49mhistory,\n\u001b[1;32m    946\u001b[0m     )\n\u001b[1;32m    947\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_hooks[\u001b[39m\"\u001b[39m\u001b[39mrequest\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_single_request(request)\n\u001b[1;32m    980\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_hooks[\u001b[39m\"\u001b[39m\u001b[39mresponse\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpx/_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1011\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1012\u001b[0m     )\n\u001b[1;32m   1014\u001b[0m \u001b[39mwith\u001b[39;00m request_context(request\u001b[39m=\u001b[39mrequest):\n\u001b[0;32m-> 1015\u001b[0m     response \u001b[39m=\u001b[39m transport\u001b[39m.\u001b[39;49mhandle_request(request)\n\u001b[1;32m   1017\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(response\u001b[39m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1019\u001b[0m response\u001b[39m.\u001b[39mrequest \u001b[39m=\u001b[39m request\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpx/_transports/default.py:232\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(request\u001b[39m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m    220\u001b[0m req \u001b[39m=\u001b[39m httpcore\u001b[39m.\u001b[39mRequest(\n\u001b[1;32m    221\u001b[0m     method\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mmethod,\n\u001b[1;32m    222\u001b[0m     url\u001b[39m=\u001b[39mhttpcore\u001b[39m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m     extensions\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mextensions,\n\u001b[1;32m    231\u001b[0m )\n\u001b[0;32m--> 232\u001b[0m \u001b[39mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m    233\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pool\u001b[39m.\u001b[39mhandle_request(req)\n\u001b[1;32m    235\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(resp\u001b[39m.\u001b[39mstream, typing\u001b[39m.\u001b[39mIterable)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    151\u001b[0m     value \u001b[39m=\u001b[39m typ()\n\u001b[1;32m    152\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen\u001b[39m.\u001b[39;49mthrow(typ, value, traceback)\n\u001b[1;32m    154\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    155\u001b[0m     \u001b[39m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[39m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[39m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[39mreturn\u001b[39;00m exc \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m value\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpx/_transports/default.py:86\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[39mraise\u001b[39;00m\n\u001b[1;32m     85\u001b[0m message \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(exc)\n\u001b[0;32m---> 86\u001b[0m \u001b[39mraise\u001b[39;00m mapped_exc(message) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n",
      "\u001b[0;31mConnectError\u001b[0m: [Errno 111] Connection refused"
     ]
    }
   ],
   "source": [
    "chain.invoke({'question':'When was the LLM Llama 3.1 trained?'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
